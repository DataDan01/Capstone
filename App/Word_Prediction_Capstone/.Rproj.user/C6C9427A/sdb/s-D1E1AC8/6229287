{
    "collab_server" : "",
    "contents" : "load(\"./data/data.RData\")\n\n## Robust backoff function for prediction\nbackoff <- function(string, end = FALSE, last = FALSE) {\n  \n  split.string <- strsplit(string, split = \" \")[[1]]\n  len <- length(split.string)\n  \n  if(last == TRUE)\n    return(split.string[len])\n  \n  if(len == 0)\n    return(\"\")\n  \n  if(len == 1)\n    return(NA)\n  \n  if(end == FALSE)\n    bo.string <- paste(split.string[2:len], collapse = \" \")\n  \n  if(end == TRUE)\n    bo.string <- paste(split.string[1:len-1], collapse = \" \")\n  \n  return(bo.string)\n}\n\n## Compiling for speed\nlibrary(compiler)\n\nboff.cmp <- cmpfun(backoff); rm(backoff)\n\n## Adjusted probabilities based on novelty, to be used in main function\ndecay.adj <- function(t = FALSE, result_table) {\n  \n  if(t == FALSE)\n    return(result_table)\n  \n  # Probability we have left to work with\n  prob.space <- 1 - result_table$Prob \n  \n  # Optimal function structure after lots of testing\n  adj <- (pi*10)^(-(log(result_table$Nov+t))/(pi*exp(1)))\n  \n  # Moving the probability towards 1 based on the novelty and previous prob\n  result_table$Adj.Prob <- (prob.space * adj) + result_table$Prob\n  \n  result_table <- result_table[order(-result_table$Adj.Prob),]\n  \n  return(result_table)\n}\n\n## Adjusted prediction function\npredict.ngram <- function(sentence, tune) {\n  \n  # Create a variable in the gloval environment to know what the original\n  # input was because the function is recursive\n  if(exists(\"original.string\", envir = .GlobalEnv) == FALSE) {\n    \n    original.string <<- sentence\n  }\n  \n  len <- length(unlist(strsplit(sentence, split = \" \")))\n  \n  # If the input is longer than 5 words, backoff since the biggest table has 6-grams\n  if(len > 5)\n    return(predict.ngram(boff.cmp(sentence), tune = tune))\n  \n  # Search the beginning of the n+1 grams for the n word input\n  test.gram <- paste0(\"^(\", sentence, \") +\")\n  \n  match.index <- grep(pattern = test.gram, x = adj.list[[len+1]]$N.Gram)\n  \n  # If there aren't any matches and the function has backed off to just one word,\n  # return the top 10 most frequent 1-grams\n  if(length(match.index) == 0 & len == 1) {\n    \n    `Result Table` <- head(adj.list[[1]], n = 10) \n    \n    results <- list(`Original Input` = original.string,\n                    `Input Used` = \"NO PREDICTION - Outputting 1-Grams\",\n                    `Back-Offs` = length(strsplit(original.string, split = \" \")[[1]]) \n                    - length(strsplit(sentence, split = \" \")[[1]]) + 1,\n                    `Seen Before?` = \"No\",\n                    `Best Predictions` = `Result Table`$N.Gram[1:5],\n                    `Result Table` = `Result Table`)\n    \n    rm(original.string, envir = .GlobalEnv)\n    \n    return(results)    \n  }\n  \n  # If there aren't any matches, backoff and try the function again\n  if(length(match.index) == 0)\n    return(predict.ngram(boff.cmp(sentence), tune = tune))\n  \n  # If there are matches, return an adjusted list of results\n  match.index <- head(match.index, n = 10)\n  \n  `Result Table` <- adj.list[[len+1]][match.index,]\n  \n  `Result Table` <- decay.adj(t = tune, result_table = `Result Table`)\n  \n  if(length(match.index) <= 5)\n    `Best Predictions` <- unlist(lapply(`Result Table`$N.Gram, boff.cmp, last = TRUE))\n  \n  if(length(match.index) > 5)\n    `Best Predictions` <- unlist(lapply(`Result Table`$N.Gram[1:5], boff.cmp, last = TRUE))\n  \n  results <- list(`Original Input` = original.string,\n                  `Input Used` = sentence,\n                  `Back-Offs` = length(strsplit(original.string, split = \" \")[[1]]) \n                  - length(strsplit(sentence, split = \" \")[[1]]),\n                  `Seen Before?` = \"Yes\",\n                  `Best Predictions` = `Best Predictions`,\n                  `Result Table` = `Result Table`)\n  \n  rm(original.string, envir = .GlobalEnv)\n  \n  return(results)  \n}\n\n## Checking the inputs\nlibrary(hunspell)\n\ninput.check <- function(sentence) {\n  \n  sentence <- tolower(sentence)\n  \n  mistakes <- unlist(hunspell(sentence))\n  \n  names(sentence) <- \"Input Used\"\n  \n  if(length(mistakes) == 0) {\n    \n    header <- \"No errors detected\"\n    \n    names(header) <- \"Message\"\n    \n    output.list <- c(as.list(header), as.list(sentence))\n    \n    output.list$Message <- noquote(output.list$Message)\n    \n    return(output.list)\n  }\n  \n  header <- noquote(\"Please consider changing the word(s):\")\n  \n  names(header) <- \"Warning\"\n  \n  suggestions <- sapply(mistakes, hunspell_suggest)\n  \n  output.list <- c(header, suggestions, sentence)\n  \n  return(output.list)\n}\n",
    "created" : 1465003036796.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3053419065",
    "id" : "6229287",
    "lastKnownWriteTime" : 1465003535,
    "last_content_update" : 1465003535613,
    "path" : "~/OneDrive/R/Capstone/App/Word_Prediction_Capstone/Prediction_Functions.R",
    "project_path" : "Prediction_Functions.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}